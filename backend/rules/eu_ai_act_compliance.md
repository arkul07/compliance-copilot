# EU AI Act Compliance Requirements

## High-Risk AI Systems

### Risk Assessment Requirements
All AI systems classified as high-risk must undergo comprehensive risk assessments before deployment. This includes:

- **Transparency obligations**: Users must be informed when interacting with AI systems
- **Human oversight**: High-risk AI systems must include human oversight mechanisms
- **Accuracy and robustness**: Systems must be designed to minimize risks and ensure accuracy
- **Data governance**: Training data must be relevant, representative, and free from bias

### Documentation Requirements
- Technical documentation must be maintained and updated
- Risk management systems must be documented
- Quality management systems must be in place
- Post-market monitoring plans must be established

### Compliance Timeline
- **Immediate**: Prohibited AI practices are banned
- **6 months**: General-purpose AI systems must comply with transparency requirements
- **12 months**: High-risk AI systems must be fully compliant
- **24 months**: All AI systems must meet full compliance requirements

## Penalties for Non-Compliance
- Up to â‚¬35 million or 7% of global annual turnover (whichever is higher)
- Administrative fines for non-compliance with documentation requirements
- Market surveillance and enforcement actions by national authorities

## Data Protection Integration
AI systems must comply with GDPR requirements:
- Lawful basis for processing personal data
- Data minimization principles
- Right to explanation for automated decisions
- Data subject rights must be respected
